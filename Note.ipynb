{"cells":[{"cell_type":"markdown","id":"75862d80","metadata":{"id":"75862d80"},"source":["- FinRL\n","    $$g(s_{i,t})$$ $s_{i,t}$: features, $g$ is optimal action, $i = 1,\\dots,N$\n","    \n","- Portfolio performance, $R_{t+1}$\n","    $$R_{t+1} = \\sum_{i=1}^N g(s_{i,t})\\times r_{i,t+1}$$\n","    \n","- Benchmark, $R^b_{t+1}$\n","    $$R^b_{t+1} = \\sum_{i=1}^N w_{i,t}\\times r_{i,t+1}$$\n","    \n","- Benchmark-adjusted return, $R_{t+1}-R^b_{t+1}$, mean, SR of $R_{t+1}-R^b_{t+1}$, $t=1,\\dots, 100$\n","    $$R_{t+1}-R^b_{t+1} = \\sum_{i=1}^N (g(s_{i,t})-w_{i,t})\\times r_{i,t+1}$$\n","    - g(s_{i,t})-w_{i,t}: active weight"]},{"cell_type":"markdown","id":"6eda4fe6","metadata":{"id":"6eda4fe6"},"source":["- Novel point 1: human transaction data, $w^{h}_{i,t}$\n","    - Plan 1: Add $w^{h}_{i,t}$ as a new feature in $s_{i,t}$, $$R^*_{t+1} = \\sum_{i=1}^N g(w^{h}_{i,t},s_{i,t})\\times r_{i,t+1}$$\n","        - Benchmark 1: FinRL performance without $human_{i,t}$: $$R_{t+1} = \\sum_{i=1}^N g(s_{i,t})\\times r_{i,t+1}$$\n","            - Implications: RF learns the knowledge from real investor actions\n","        - Benchmark 2: Human portfolio performance, $w^{h}_{i,t}$: $$R^h_{t+1} = \\sum_{i=1}^N w^h_{i,t}\\times r_{i,t+1}$$\n","            - Implications: RF improves the investment decision of real investors\n","    - Plan 2: Use $w^{h}_{i,t}$ as the only feature under FinRL, $$R^*_{t+1} = \\sum_{i=1}^N g(w^{h}_{i,t})\\times r_{i,t+1}$$\n","        - Benchmark: Human portfolio performance, $w^{h}_{i,t}$: $$R^h_{t+1} = \\sum_{i=1}^N w^h_{i,t}\\times r_{i,t+1}$$\n","    - Plan 3: \n","        - Step 1: $\\hat{w}^{h}_{i,t} = f^*(s_{i,t})$, f is trained by some supervised ML models based on data $Y = w^h_t$ and $X = s_{i,t}$, $$s_{i,t} = f^{*-1}(\\hat{w}^{h}_{i,t})+ (s_{i,t}-f^{*-1}(\\hat{w}^{h}_{i,t}))$$\n","            - $E[{r_{i,t+1}|s_{i,t}}]$\n","        - Step 2: $\\hat{w}^{h}_{i,t}$ as the only feature under FinRL, $$R^*_{t+1} = \\sum_{i=1}^N g(f^*(s_{i,t}))\\times r_{i,t+1}$$\n","            - $G(s_t) = g(f^*(s_t))$\n","\n","    - Plan 4: \n","        - Step 1: $\\hat{w}^{h}_{i,t} = f(s_{i,t})$, f is trained by some supervised ML models based on data $w^h_t$ and $s_{i,t}$\n","            - Must be Neural Network\n","            - $f = \\Sigma \\phi_{i,t}\\times s_{i,t}$\n","        - Step 2: \n","            - $G(s_t)$"]},{"cell_type":"markdown","id":"7f567768","metadata":{"id":"7f567768"},"source":["- w_1: insider, who knows private information $p$ and $s$\n","- w_2: portfolio manager, who only knows $s$\n","\n","- Plan 1: $g(w_1,s)$ is better than $g(w_2,s)$\n","- Plan 3&4: $g(w_1,s)$ is equal to $g(w_2,s)$, information set = $\\{s_t: \\min_f MSE(|w^{h}_{i,t}-f(s_{i,t})|\\}$)"]},{"cell_type":"markdown","id":"c623030b","metadata":{"id":"c623030b"},"source":["- Most uninformative $s_{i,t}$: $E[{r_{i,t+1}|s_{i,t}}] = 0$\n","- If $s_{i,t}$ is informative, then $E[{r_{i,t+1}|s_{i,t}}] = f(s_{i,t})$\n","    - If $\\hat{w}^{h}_{i,t}$ contains all information about $r_{i,t+1}$, then $E[r_{i,t+1}|\\hat{w}^{h}_{i,t},s_{i,t}] = E[r_{i,t+1}|\\hat{w}^{h}_{i,t}]$"]},{"cell_type":"code","execution_count":null,"id":"9c0d3dab","metadata":{"id":"9c0d3dab"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}